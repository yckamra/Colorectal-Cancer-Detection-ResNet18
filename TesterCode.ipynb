{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b5hBGxvbBN-D"
      },
      "outputs": [],
      "source": [
        "import os  # For file manipulation\n",
        "import torch  # Machine learning library\n",
        "import numpy as np  # For math library and matrices\n",
        "import random  # For random operations\n",
        "\n",
        "from PIL import Image  # For image processing\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from torchvision import transforms, models  # For image transformations and pre-trained models\n",
        "from torch.utils.data import Dataset, DataLoader  # For creating custom datasets and managing batches\n",
        "import torch.nn as nn  # For building neural networks\n",
        "import matplotlib.pyplot as plt  # For graphing\n",
        "from google.colab import drive  # For accessing Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enable Colab's local cuda GPU do the following: Go to Runtime > Change runtime type > Set Hardware accelerator to GPU > Save."
      ],
      "metadata": {
        "id": "d-0UksUHDgii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available()) # See if cuda GPU is accessible"
      ],
      "metadata": {
        "id": "pprCC54LDejO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') # Mounting Google Drive\n",
        "# Copy dataset from Google Drive to Colab's local storage (if not too large)\n",
        "!cp -r /content/drive/MyDrive/TestDataset /content/dataset/\n",
        "\n",
        "drive_path = '/content/dataset/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN-geBEmBS7Y",
        "outputId": "34ff0422-5438-4eeb-bb48-4b14c87c7fae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our trained model from Google Drive\n",
        "my_model = models.resnet18(weights=None)\n",
        "model_path = '/content/drive/MyDrive/COMP432Project/resnet18_model_V1.pth'\n",
        "my_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
        "my_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uKGu-f_CiK3",
        "outputId": "8a143980-4224-47c6-f184-cbe0c1f1195c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c2d37205f0f2>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  my_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_path_array(image_directory):\n",
        "  # Empty list for all our processed images\n",
        "  image_paths = []\n",
        "\n",
        "  # Traverse the directory and subdirectories to find all .tif files\n",
        "  for root, dirs, files in os.walk(image_directory):\n",
        "      for filename in files:\n",
        "          if filename.endswith(\".tif\"):\n",
        "              # Get full image path\n",
        "              image_path = os.path.join(root, filename)\n",
        "              image_paths.append(image_path)\n",
        "\n",
        "\n",
        "  return image_paths"
      ],
      "metadata": {
        "id": "-qHeWZSPCasQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Get the paths of all images to allow for splitting into train and test and random shuffling\n",
        "  MUS_paths = create_image_path_array('/content/drive/MyDrive/TestDataset/colorectal_cancer/MUS')\n",
        "  NORM_paths = create_image_path_array('/content/drive/MyDrive/TestDataset/colorectal_cancer/NORM')\n",
        "  STR_paths = create_image_path_array('/content/drive/MyDrive/TestDataset/colorectal_cancer/STR')\n",
        "\n",
        "  # Create output labels for our images\n",
        "  MUS_labels = [0] * len(MUS_paths)\n",
        "  NORM_labels = [1] * len(NORM_paths)\n",
        "  STR_labels = [2] * len(STR_paths)\n",
        "\n",
        "  # Combine all paths and labels into one list\n",
        "  all_paths = MUS_paths + NORM_paths + STR_paths\n",
        "  all_labels = MUS_labels + NORM_labels + STR_labels\n",
        "\n",
        "  # Shuffle our training data\n",
        "  all_paths, all_labels = shuffle(all_paths, all_labels, random_state=42)\n",
        "  print(len(all_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrtrPUyKBYMT",
        "outputId": "3f79b031-921e-4d19-af37-5b3a1feac1b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load the image\n",
        "        image = Image.open(self.image_paths[index]).convert('RGB')\n",
        "\n",
        "        # Apply our 'preprocess' transformations (i.e. resizing, normalization)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Get the respective label\n",
        "        label = self.labels[index]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Preprocessing transformations for ResNet input\n",
        "preprocess = transforms.Compose([\n",
        "  transforms.Resize(256),               # Resize to 256 pixels on shorter side\n",
        "  transforms.CenterCrop(224),           # Crop center to 224x224\n",
        "  transforms.ToTensor(),                # Convert to PyTorch tensor\n",
        "  transforms.Normalize(                 # Normalize using ImageNet mean and std\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        "  ),\n",
        "])\n",
        "# Create dataset\n",
        "test_dataset = ImageDataset(all_paths, all_labels, transform=preprocess)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "3tg9_i4eDwNa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility to calculate accuracy\n",
        "def calculate_accuracy(predictions, labels):\n",
        "    return (predictions == labels).sum().item() / len(labels)"
      ],
      "metadata": {
        "id": "ynJfcWkgE_md"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "my_model.to(device)  # Move model to the GPU\n",
        "my_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Evaluate the model on the entire dataset\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move images and labels to the GPU\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = my_model(images)\n",
        "\n",
        "        # Get predicted class (highest score)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Append predictions and labels to lists\n",
        "        all_predictions.extend(preds.cpu().numpy())  # Move to CPU for appending\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "sRgPGGwwD9r-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall accuracy\n",
        "accuracy = calculate_accuracy(np.array(all_predictions), np.array(all_labels))\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "report = classification_report(all_labels, all_predictions, target_names=[\"MUS\", \"NORM\", \"STR\"])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhA2uN55Efrm",
        "outputId": "bca72482-2496-42a4-8040-9cbeec80b9bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         MUS       1.00      1.00      1.00        34\n",
            "        NORM       1.00      1.00      1.00        33\n",
            "         STR       1.00      1.00      1.00        33\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2lDndVJCFWca"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}